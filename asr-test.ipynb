{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\r\n",
    "# import soundfile as sf\r\n",
    "import librosa\r\n",
    "import torch\r\n",
    "\r\n",
    "print('load model and tokenizer')\r\n",
    "\r\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\r\n",
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\r\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\r\n",
    "model = model.to(device)\r\n",
    "\r\n",
    "print('load audio')\r\n",
    "audio, rate = librosa.load(\"output.wav\", sr = 16000)\r\n",
    "\r\n",
    "print('tokenize')\r\n",
    "input_values = tokenizer(audio, return_tensors = \"pt\").input_values.to(device)\r\n",
    "\r\n",
    "print('prediction')\r\n",
    "logits = model(input_values).logits\r\n",
    "\r\n",
    "print('take argmax and decode')\r\n",
    "prediction = torch.argmax(logits, dim = -1)\r\n",
    "transcription = tokenizer.batch_decode(prediction)[0]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "load model and tokenizer\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "c:\\Users\\clara\\Desktop\\greenfield_overall\\asr\\asr-venv\\lib\\site-packages\\transformers\\models\\wav2vec2\\tokenization_wav2vec2.py:417: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  warnings.warn(\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "load audio\n",
      "tokenize\n",
      "prediction\n",
      "take argmax and decode\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import pyaudio\r\n",
    "p = pyaudio.PyAudio()\r\n",
    "info = p.get_host_api_info_by_index(0)\r\n",
    "numdevices = info.get('deviceCount')\r\n",
    "for i in range(0, numdevices):\r\n",
    "        if (p.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:\r\n",
    "            print( \"Input Device id \", i, \" - \", p.get_device_info_by_host_api_device_index(0, i).get('name'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input Device id  0  -  Microsoft Sound Mapper - Input\n",
      "Input Device id  1  -  Microphone Array (Realtek(R) Au\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import torch, gc\r\n",
    "\r\n",
    "gc.collect()\r\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(transcription)\r\n",
    "#open text file\r\n",
    "text_file = open(\"cna_pred.txt\", \"w\")\r\n",
    " \r\n",
    "#write string to file\r\n",
    "text_file.write(transcription)\r\n",
    " \r\n",
    "#close file\r\n",
    "text_file.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ONLY DELLY AND HI PAY OUR RAMPING A FREIGT TALK WHICH CULD BRING AS SEVEN QI IE BILLYA DOLLARS SAMYTE AT TA BACT RETED INDIA BY THE AN OF A YEAR BID CID BECOME ANOTHER FA FOINT  BETWEEN YOU DALLY AND BA JAKE A RELATIONS REMAIN HEN A TRUE A FILL DEALING WITH A BORDE DISPUTE FAN LASTDA AND HEMALAYAN REGION A MODER ME APON YOUR HAV MORE MEDE REPORT SOR GEST INDIA AND FIVARN ARE AN TALKS OVER AN A GREEMEN THAT COULD HELT OE DRES SNE ALLY TO TET IP SHIP SHORT AF FOR A BROOMBOR REFORTH OFFICIALS IN OUJALLY AND SIE TAY A MET A GEEANT WY TO THE CAFFEDEEL THAT WOULD HAL GRIN AT SHIP FLANT TO INDIA EXPECTEDLY WORTH TAVEN CON FIVE FBIDION DOLLARS IT WILL HEL  TE LIE SHIP WOR EVERYING FROM FIVE TY TAVIVEWIT TO WE THAT TRACART IN DHEAS O REBOTH OF THES SCALTIN FOFF ABLE LOCATION FOR THE PLANT THA GOVERMENT ES FOMM TACK BREAT TAT OF WE DUCTIONS AS WELL A HE C MI MIN TO PROVIDE FIFTY PE TANT O THE CAPITAL EXTAN YCANI BY TWENTY  TWENTY THREE CARRENTLY INDIA IN FORT ALL OF THET SANY CONDUCTORS BUT DEMAND ISEBECTE TO CORT RO FORTH A HUNDRED BILLION DOLLARS BY TWENTY TWENTY FIVE NWE NEW INTRENTTO THE FIELD INDIA HAS BEN TA AGRESSIBLY WOIN COMPENE THAT ME SANY CONDUCORS SELDIN THER TO SATUP SHOP YAR ONLY THE IATHER GOVERMEN CAN SOUNTE WOS TIN DUC WIT TWINTY FARMS AN WAT MOLIN IN SANTIV FOR THE SEC ORS WELE WE T MODY THE CAFTI LAF WE WITH SY YOLS OF AMELE CON FIRM AND USUAL REPBOTH OF THE OLT OTA OUT OF THE SERS T EVER IN PORSON FOMMA OF CORD LEADER WHERE INDIA YOUES OF TRALLIA AND JAPAN AGREETO TI CURE SUPPLI THANS FOR ANY CONDUCTORS A MOVE IN THAT CONTINING CHINA INTOENT IN THE ECTOR AT EAL WITH SI ONT COUL BE REPBOR ODA TACY CERSER TO A LARGER MORE CAN TE TWAT FACT WITH TWEIN THE TO COUNTRY TY AND IN WE TOUTHROFICIALS IN Y INDIAN COMMER ANI RY FOR THER WORDS NO RESPONS THIS MARKS OF TID ISITINSHIPS TIN HOW INDIA CHOSIN TO INGATE WIT COUNTRY IN AUTYTASA INTHE AFTERMOUT OF THE BORDE SAND OF WIT PAGING WHILE I VONE HAD LONG POSUED INDIA NEW DALLY HAV PBENHEATITANT ABOUT WOPENLY ENGAGINWI TIE A EXFOLTY THE CERS HAT WAS BOLOWED ABOUT ANGOR INGAGING WHICH TIN THE ALLANT COUNTRY HAT FAT OF THE FONTALETELY BUT NOUND I TETA THAT HEASITIN AND BETTECAN MADIA ING OF THE PAFT NEING ACONIA SEANNY NEW DALLY\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def wer(ref, hyp ,debug=False):\r\n",
    "    r = ref.split()\r\n",
    "    h = hyp.split()\r\n",
    "    #costs will holds the costs, like in the Levenshtein distance algorithm\r\n",
    "    costs = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\r\n",
    "    # backtrace will hold the operations we've done.\r\n",
    "    # so we could later backtrace, like the WER algorithm requires us to.\r\n",
    "    backtrace = [[0 for inner in range(len(h)+1)] for outer in range(len(r)+1)]\r\n",
    " \r\n",
    "    OP_OK = 0\r\n",
    "    OP_SUB = 1\r\n",
    "    OP_INS = 2\r\n",
    "    OP_DEL = 3\r\n",
    "\r\n",
    "    DEL_PENALTY = 1\r\n",
    "    INS_PENALTY = 1\r\n",
    "    SUB_PENALTY = 1\r\n",
    "     \r\n",
    "    # First column represents the case where we achieve zero\r\n",
    "    # hypothesis words by deleting all reference words.\r\n",
    "    for i in range(1, len(r)+1):\r\n",
    "        costs[i][0] = DEL_PENALTY*i\r\n",
    "        backtrace[i][0] = OP_DEL\r\n",
    "         \r\n",
    "    # First row represents the case where we achieve the hypothesis\r\n",
    "    # by inserting all hypothesis words into a zero-length reference.\r\n",
    "    for j in range(1, len(h) + 1):\r\n",
    "        costs[0][j] = INS_PENALTY * j\r\n",
    "        backtrace[0][j] = OP_INS\r\n",
    "     \r\n",
    "    # computation\r\n",
    "    for i in range(1, len(r)+1):\r\n",
    "        for j in range(1, len(h)+1):\r\n",
    "            if r[i-1] == h[j-1]:\r\n",
    "                costs[i][j] = costs[i-1][j-1]\r\n",
    "                backtrace[i][j] = OP_OK\r\n",
    "            else:\r\n",
    "                substitutionCost = costs[i-1][j-1] + SUB_PENALTY # penalty is always 1\r\n",
    "                insertionCost    = costs[i][j-1] + INS_PENALTY   # penalty is always 1\r\n",
    "                deletionCost     = costs[i-1][j] + DEL_PENALTY   # penalty is always 1\r\n",
    "                 \r\n",
    "                costs[i][j] = min(substitutionCost, insertionCost, deletionCost)\r\n",
    "                if costs[i][j] == substitutionCost:\r\n",
    "                    backtrace[i][j] = OP_SUB\r\n",
    "                elif costs[i][j] == insertionCost:\r\n",
    "                    backtrace[i][j] = OP_INS\r\n",
    "                else:\r\n",
    "                    backtrace[i][j] = OP_DEL\r\n",
    "                 \r\n",
    "    # back trace though the best route:\r\n",
    "    i = len(r)\r\n",
    "    j = len(h)\r\n",
    "    numSub = 0\r\n",
    "    numDel = 0\r\n",
    "    numIns = 0\r\n",
    "    numCor = 0\r\n",
    "    if debug:\r\n",
    "        print(\"OP\\tREF\\tHYP\")\r\n",
    "        lines = []\r\n",
    "    while i > 0 or j > 0:\r\n",
    "        if backtrace[i][j] == OP_OK:\r\n",
    "            numCor += 1\r\n",
    "            i-=1\r\n",
    "            j-=1\r\n",
    "            if debug:\r\n",
    "                lines.append(\"OK\\t\" + r[i]+\"\\t\"+h[j])\r\n",
    "        elif backtrace[i][j] == OP_SUB:\r\n",
    "            numSub +=1\r\n",
    "            i-=1\r\n",
    "            j-=1\r\n",
    "            if debug:\r\n",
    "                lines.append(\"SUB\\t\" + r[i]+\"\\t\"+h[j])\r\n",
    "        elif backtrace[i][j] == OP_INS:\r\n",
    "            numIns += 1\r\n",
    "            j-=1\r\n",
    "            if debug:\r\n",
    "                lines.append(\"INS\\t\" + \"****\" + \"\\t\" + h[j])\r\n",
    "        elif backtrace[i][j] == OP_DEL:\r\n",
    "            numDel += 1\r\n",
    "            i-=1\r\n",
    "            if debug:\r\n",
    "                lines.append(\"DEL\\t\" + r[i]+\"\\t\"+\"****\")\r\n",
    "    if debug:\r\n",
    "        lines = reversed(lines)\r\n",
    "        for line in lines:\r\n",
    "            print(line)\r\n",
    "        print(\"#cor \" + str(numCor))\r\n",
    "        print(\"#sub \" + str(numSub))\r\n",
    "        print(\"#del \" + str(numDel))\r\n",
    "        print(\"#ins \" + str(numIns))\r\n",
    "    wer_result = round( (numSub + numDel + numIns) / (float) (len(r)), 3)\r\n",
    "    return {'WER':wer_result, 'Cor':numCor, 'Sub':numSub, 'Ins':numIns, 'Del':numDel}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "with open('cna_GT.txt', 'r') as file:\r\n",
    "    cna_GT = file.read().replace('\\n', ' ')\r\n",
    "\r\n",
    "with open('cna_pred.txt', 'r') as file:\r\n",
    "    cna_pred = file.read().replace('\\n', '')\r\n",
    "\r\n",
    "WER = wer(cna_GT, cna_pred)\r\n",
    "\r\n",
    "print(WER)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'WER': 1.096, 'Cor': 0, 'Sub': 394, 'Ins': 38, 'Del': 0}\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('asr-venv': venv)"
  },
  "interpreter": {
   "hash": "5edc988c3b771adb805e599755a45dac721a97e6edd49ca39720051b710ed818"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}